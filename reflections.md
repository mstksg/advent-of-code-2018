Reflections
===========

<!--
This file generated by the build script at ./Build.hs from the files in
./reflections.  If you want to edit this, edit those instead!
-->

*[2016][]* / *[2017][]* / *2018* / *[2019][]* / *[2020][]*

[2016]: https://github.com/mstksg/advent-of-code-2016/blob/master/reflections.md
[2017]: https://github.com/mstksg/advent-of-code-2017/blob/master/reflections.md
[2019]: https://github.com/mstksg/advent-of-code-2019/blob/master/reflections.md
[2020]: https://github.com/mstksg/advent-of-code-2020/blob/master/reflections.md

[Available as an RSS Feed][rss]

[rss]: http://feeds.feedburner.com/jle-advent-of-code-2018

Table of Contents
-----------------

* [Day 1](#day-1)
* [Day 2](#day-2)
* [Day 3](#day-3)
* [Day 4](#day-4)
* [Day 5](#day-5)
* [Day 6](#day-6)
* [Day 7](#day-7) *(no reflection yet)*
* [Day 8](#day-8)
* [Day 9](#day-9)
* [Day 10](#day-10)
* [Day 11](#day-11)
* [Day 12](#day-12)
* [Day 13](#day-13)
* [Day 14](#day-14) *(no reflection yet)*
* [Day 15](#day-15)
* [Day 16](#day-16)
* [Day 17](#day-17) *(no reflection yet)*
* [Day 18](#day-18) *(no reflection yet)*
* [Day 19](#day-19) *(no reflection yet)*
* [Day 20](#day-20)
* [Day 21](#day-21) *(no reflection yet)*
* [Day 22](#day-22) *(no reflection yet)*
* [Day 23](#day-23) *(no reflection yet)*
* [Day 24](#day-24) *(no reflection yet)*
* [Day 25](#day-25) *(no reflection yet)*

Day 1
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day01.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d01p]* / *[Code][d01g]* / *[Rendered][d01h]*

[d01p]: https://adventofcode.com/2018/day/1
[d01g]: https://github.com/mstksg/advent-of-code-2018/blob/master/src/AOC/Challenge/Day01.hs
[d01h]: https://mstksg.github.io/advent-of-code-2018/src/AOC.Challenge.Day01.html

Day 1 is a pretty straightforward functional programming sort of pipeline.

The first part is just a sum:

```haskell
day01a :: [Int] -> Int
day01a = sum
```

The second part is a little tricker, but we can get a list of running sums with
`scanl (+) 0`.  We need to find the first *repeated* item in that list of
running totals.  We can do this using explicit recursion down the linked list:

```haskell
import qualified Data.Set as S

firstRepeated :: [Int] -> Maybe Int
firstRepeated = go S.empty
  where
    go seen (x:xs)
      | x `S.member` seen = Just x                      -- this is it, chief
      | otherwise         = go (x `S.insert` seen) xs   -- we have to look furhter
```

And so then we have our full pipeline.  We do need to remember to loop the input
list infinitely by using `cycle`.

```haskell
day01b :: [Int] -> Maybe Int
day01b = firstRepeated . scanl (+) 0 . cycle
```

We do need a parser, and we can leverage `readMaybe`:

```haskell
parseItem :: String -> Maybe Int
parseItem = readMaybe . filter (/= '+')

parseList :: String -> Maybe [Int]
parseList = traverse parseItem . lines
```

One small extra bonus note --- as a Haskeller, we are always taught to be
afraid of explicit recursion.  So, the implementation of `firstRepeated` is a
little unsettling.  We can write it using a catamorphism instead, from the
*recursion-schemes* library:

```haskell
firstRepeated :: [Int] -> Maybe Int
firstRepeated xs = cata go xs S.empty
  where
    go  :: ListF Int (Set Int -> Maybe Int)
        -> Set Int
        -> Maybe Int
    go Nil _              = Nothing
    go (Cons x searchRest) seen
      | x `S.member` seen = Just x                          -- this is it, chief
      | otherwise         = searchRest (x `S.insert` seen)  -- we have to look further
```

`cata` wraps up a very common sort of recursion, so we can safely write our
`firstRepeated` as a non-recursive function.


### Day 1 Benchmarks

```
>> Day 01a
benchmarking...
time                 1.761 μs   (1.760 μs .. 1.762 μs)
                     1.000 R²   (1.000 R² .. 1.000 R²)
mean                 1.759 μs   (1.758 μs .. 1.760 μs)
std dev              3.371 ns   (2.754 ns .. 4.710 ns)

* parsing and formatting times excluded

>> Day 01b
benchmarking...
time                 109.6 ms   (105.4 ms .. 113.5 ms)
                     0.998 R²   (0.995 R² .. 1.000 R²)
mean                 107.2 ms   (105.7 ms .. 108.6 ms)
std dev              2.580 ms   (1.896 ms .. 3.501 ms)

* parsing and formatting times excluded
```



Day 2
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day02.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d02p]* / *[Code][d02g]* / *[Rendered][d02h]*

[d02p]: https://adventofcode.com/2018/day/2
[d02g]: https://github.com/mstksg/advent-of-code-2018/blob/master/src/AOC/Challenge/Day02.hs
[d02h]: https://mstksg.github.io/advent-of-code-2018/src/AOC.Challenge.Day02.html

Day 2 part 1 works out nicely in a functional paradigm because it can be seen
as just building a couple of frequency tables.

I often use this function to generate a frequency table of values in a list:

```haskell
import qualified Data.Map as M

freqs :: [a] -> Map a Int
freqs = M.fromListWith (+) . map (,1)
```

Day 2 part 1 is then to:

1.  Build a frequency map for chars for each line
2.  Aggregate all of the seen frequencies in each line
3.  Build a frequency map of the seen frequencies
4.  Look up how often freq 2 and freq 3 occurred, and then multiply

So we have:

```haskell
day02a :: [String] -> Maybe Int
day02a = mulTwoThree
       . freqs
       . concatMap (nubOrd . M.elems . freqs)

mulTwoThree :: Map Int Int -> Maybe Int
mulTwoThree mp = (*) <$> M.lookup 2 mp <*> M.lookup 3 mp
```

Part 2 for this day is pretty much the same as Part 2 for day 1, only instead
of finding the first item that has already been seen, we find the first item
who has any *neighbors* who had already been seen.

```haskell
import           Control.Lens
import qualified Data.Set as S

firstNeighbor :: [String] -> Maybe (String, String)
firstNeighbor = go S.empty
  where
    go seen (x:xs) = case find (`S.member` seen) (neighbors x) of
        Just n  -> Just (x, n)
        Nothing -> go (x `S.insert` seen) xs
    go _ [] = Nothing

neighbors :: String -> [String]
neighbors xs = [ xs & ix i .~ newChar
               | i       <- [0 .. length xs - 1]
               | newChar <- ['a'..'z']
               ]
```

`firstNeighbor` will return the first item who has a neighbor that has already
been seen, along with that neighbor.

The answer we need to return is the common letters between the two strings, so
we can write a function to only keep common letters between two strings:

```haskell
onlySame :: String -> String -> String
onlySame xs = catMaybes . zipWith (\x y -> x <$ guard (x == y)) xs

-- > onlySame "abcd" "abed" == "abd"
```

And that's pretty much the entire pipeline:

```haskell
day02a :: [String] -> Maybe String
day02a = fmap (uncurry onlySame) . firstNeighbor
```

Parsing is just `lines :: String -> [String]`, which splits a string on lines.


### Day 2 Benchmarks

```
>> Day 02a
benchmarking...
time                 764.6 μs   (714.9 μs .. 805.5 μs)
                     0.972 R²   (0.954 R² .. 0.985 R²)
mean                 832.2 μs   (799.6 μs .. 888.5 μs)
std dev              140.8 μs   (97.40 μs .. 211.6 μs)
variance introduced by outliers: 90% (severely inflated)

* parsing and formatting times excluded

>> Day 02b
benchmarking...
time                 50.44 ms   (48.40 ms .. 52.57 ms)
                     0.994 R²   (0.987 R² .. 0.998 R²)
mean                 47.54 ms   (45.59 ms .. 49.27 ms)
std dev              3.462 ms   (2.728 ms .. 4.515 ms)
variance introduced by outliers: 22% (moderately inflated)

* parsing and formatting times excluded
```



Day 3
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day03.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d03p]* / *[Code][d03g]* / *[Rendered][d03h]*

[d03p]: https://adventofcode.com/2018/day/3
[d03g]: https://github.com/mstksg/advent-of-code-2018/blob/master/src/AOC/Challenge/Day03.hs
[d03h]: https://mstksg.github.io/advent-of-code-2018/src/AOC.Challenge.Day03.html

Day 3 brings back one of my favorite data structures in Haskell -- `Map (Int,
Int)`!  It's basically a sparse grid.  It maps coordinates to values at each
coordinate.

We're going to use `V2 Int` (from *[linear][]*) instead of `(Int, Int)` (they're
the same thing), because we get to use the overloaded `+` operator to do
point-wise addition.  Let's also define a rectangle specification and claim
record type to keep things clean:

[linear]: https://hackage.haskell.org/package/linear

```haskell
type Coord = V2 Int

data Rect = R { rStart :: Coord
              , rSize  :: Coord
              }

data Claim = C { cId   :: Int
               , cRect :: Rect
               }
```

Now, we want to make a function that, given a rectangle, produces a list of
every coordinate in that rectangle.  We can take advantage of `range` from
*Data.Ix*, which enumerates all coordinates between two corners:

```haskell
tiles :: Rect -> [Coord]
tiles (R start size) = range (topLeft, bottomRight)
  where
    topLeft     = start
    bottomRight = start + size - 1          -- V2 has a Num instance
```

Now we can stake all of the claims and lay all of the tiles down into a `Map
Coord Int`, a frequency map of coordinates that have been claimed (and how many
times they have been claimed):

```haskell
layTiles :: [Rect] -> Map Coord Int
layTiles = freqs . concatMap tiles
```

(Reusing `freqs` from Day 2)

From there, we need to count how many frequencies we observe are greater
than 1.  We can do that by filtering and counting how many are left.

```haskell
import qualified Data.Map as M

day03a :: [Rect] -> Int
day03a = length . filter (>= 2) . M.elems . layTiles
```

For `day03`, we can use `find` to search our list of claims by id's,
`[(Int, Rect)]` and find any claim that is completely non-overlapping.

We can check if a claim is non-overlapping or not by checking our map of staked
tiles and making sure that every square in the claim has exactly frequency `1`.

```haskell
noOverlap :: Map Coord Int -> Rect -> Bool
noOverlap tilesClaimed r = all isAlone (tiles r)
  where
    isAlone c = M.lookup c tilesClaimed == Just 1
```

And that's our Part 2:

```haskell
day03b :: [Claim] -> Maybe Int
day03b ts = cId <$> find (noOverlap stakes . cRect) ts
  where
    stakes = layTiles (map snd ts)
```

Parsing for this one is a little tricky, but we can get away with just clearing
out all non-digit characters and using `words` to split up a string into its
constituent words, and `readMaybe` to read each one.

```haskell
parseLine :: String -> Maybe Claim
parseLine = mkLine
          . mapMaybe readMaybe
          . words
          . map onlyDigits
  where
    mkLine [i,x0,y0,w,h] = Just $ Claim i (R (V2 x0 y0) (V2 w h))
    mkLine _             = Nothing
    onlyDigits c
      | isDigit c = c
      | otherwise = ' '
```


### Day 3 Benchmarks

```
>> Day 03a
benchmarking...
time                 342.4 ms   (259.5 ms .. 381.0 ms)
                     0.993 R²   (0.982 R² .. 1.000 R²)
mean                 351.6 ms   (340.2 ms .. 362.1 ms)
std dev              12.64 ms   (7.794 ms .. 15.36 ms)
variance introduced by outliers: 19% (moderately inflated)

>> Day 03b
benchmarking...
time                 319.3 ms   (298.8 ms .. 358.2 ms)
                     0.993 R²   (0.961 R² .. 1.000 R²)
mean                 318.6 ms   (312.6 ms .. 329.1 ms)
std dev              10.84 ms   (2.646 ms .. 14.76 ms)
variance introduced by outliers: 16% (moderately inflated)
```



Day 4
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day04.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d04p]* / *[Code][d04g]* / *[Rendered][d04h]*

[d04p]: https://adventofcode.com/2018/day/4
[d04g]: https://github.com/mstksg/advent-of-code-2018/blob/master/src/AOC/Challenge/Day04.hs
[d04h]: https://mstksg.github.io/advent-of-code-2018/src/AOC.Challenge.Day04.html

Day 4 was fun because it's something that, on the surface, sounds like it
requires a state machine to run through a stateful log and accumulate a bunch
of time sheets.

However, if we think of the log as just a stream of tokens, we can look at at
it as *parsing* this stream of tokens into time sheets -- no state or mutation
required.

First, the types at play:

```haskell
type Minute = Finite 60

type TimeCard = Map Minute Int

data Time = T { _tYear   :: Integer
              , _tMonth  :: Integer
              , _tDay    :: Integer
              , _tHour   :: Finite 24
              , _tMinute :: Minute
              }
  deriving (Eq, Ord)

newtype Guard = G { _gId :: Int }
  deriving (Eq, Ord)

data Action = AShift Guard
            | ASleep
            | AWake
```

Note that we have a bunch of "integer-like" quantities going on: the
year/month/day/hour/minute, the guard ID, and the "frequency" in the `TimeCard`
frequency map.  Just to help us accidentally not mix things up (like I
personally did many times), we'll make them all different types.  A `Minute` is
a `Finite 60` (`Finite 60`, from the *finite-typelits* library, is a type that
is basically the integers limited from 0 to 59).  Our hours are `Finite 24`.
Our Guard ID will be a newtype `Guard`, just so we don't accidentally mix it up
with other types.

Now, after parsing our input, we have a `Map Time Action`: a map of times to
actions committed at that time.  The fact that we store it in a `Map` ensures
that the log items are ordered and unique.

We now essentially want to parse a stream of `(Time, Action)` pairs into a `Map
Guard TimeCard`: A map of `TimeCard`s indexed by the guard that has that time
card.

To do that, we'll use the *parsec* library, which lets us parse over streams of
arbitrary token type.  Our parser type will take a `(Time, Action)` stream:

```haskell
import qualified Text.Parsec as P

type Parser = P.Parsec [(Time, Action)] ()
```

A `Parser Blah` will be a parser that, given a stream of `(Time, Action)`
pairs, will aggregate them into a value of type `Blah`.

Turning our stream into a `Map Guard TimeCard` is now your standard
run-of-the-mill parser combinator program.

```haskell
-- | We define a nap as an `ASleep` action followed by an `AWake` action.  The
-- result is a list of minutes slept.
nap :: Parser [Minute]
nap = do
    (T _ _ _ _ m0, ASleep) <- P.anyToken
    (T _ _ _ _ m1, AWake ) <- P.anyToken
    pure [m0 .. m1 - 1]     -- we can do this because m0 < m1 always in the
                            --   input data.

-- | We define a a guard's shift as a `AShift g` action, followed by
-- "many" naps.  The result is a list of minutes slept along with the ID of the
-- guard that slept them.
guardShift :: Parser (Guard, [Minute])
guardShift = do
    (_, AShift g) <- P.anyToken
    napMinutes    <- concat <$> many (P.try nap)
    pure (g, napMinutes)

-- | A log stream is many guard shifts. The result is the accumulation of all
-- of those shifts into a massive `Map Guard [Minute]` map, but turning all of
-- those [Minutes] into a frequency map instead by using `fmap freqs`.
buildTimeCards :: Parser (Map Guard TimeCard)
buildTimeCards = do
    shifts <- M.fromListWith (++) <$> many guardShift
    pure (fmap freqs shifts)
```

We re-use the handy `freqs :: Ord a => [a] -> Map a Int` function, to build a
frequency map, from Day 2.

We can run a parser on our `[(Time, Action)]` stream by using `P.parse ::
Parser a -> [(Time, Action)] -> SourceName -> Either ParseError a`.

The rest of the challenge involves "the X with the biggest Y" situations, which
all boil down to "The key-value pair with the biggest *some property of
value*".

We can abstract over this by writing a function that will find the key-value
pair with the biggest *some property of value*:

```haskell
import qualified Data.List.NonEmpty as NE

maximumValBy
    :: (a -> a -> Ordring)  -- ^ function to compare values
    -> Map k a
    -> Maybe (k, a)         -- ^ biggest key-value pair, using comparator function
maximumValBy c = fmap (maximumBy (c `on` snd)) . NE.nonEmpty . M.toList

-- | Get the key-value pair with highest value
maximumVal :: Ord a => Map k a -> Maybe (k, a)
maximumVal = maximumValBy compare
```

We use `fmap (maximumBy ...) . NE.nonEmpty` as basically a "safe maximum",
allowing us to return `Nothing` in the case that the map was empty. This works
because `NE.nonEmpty` will return `Nothing` if the list was empty, and `Just`
otherwise...meaning that `maximumBy` is safe since it is never given to a
non-empty list.

The rest of the challenge is just querying this `Map Guard TimeCard` using some
rather finicky applications of the predicates specified by the challenge.
Luckily we have our safe types to keep us from mixing up different concepts by
accident.

```haskell
eitherToMaybe :: Either e a -> Maybe a
eitherToMaybe = either (const Nothing) Just

day04a :: Map Time Action -> Maybe Int
day04a logs = do
    -- build time cards
    timeCards               <- eitherToMaybe $ P.parse buildTimeCards "" (M.toList logs)
    -- get the worst guard/time card pair, by finding the pair with the
    --   highest total minutes slept
    (worstGuard , timeCard) <- maximumValBy (comparing sum) timeCards
    -- get the minute in the time card with the highest frequency
    (worstMinute, _       ) <- maximumVal timeCard
    -- checksum
    pure $ _gId worstGuard * fromIntegral worstMinute

day04b :: Map Time Action -> Maybe Int
day04b logs = do
    -- build time cards
    timeCards                      <- eitherToMaybe $ P.parse buildTimeCards "" (M.toList logs)
    -- build a map of guards to their most slept minutes
    let worstMinutes :: Map Guard (Minute, Int)
        worstMinutes = M.mapMaybe maximumVal timeCards
    -- find the guard with the highest most-slept-minute
    (worstGuard, (worstMinute, _)) <- maximumValBy (comparing snd) worstMinutes
    -- checksum
    pure $ _gId worstGuard * fromIntegral worstMinute
```

Like I said, these are just some complicated queries, but they are a direct
translation of the problem prompt.  The real interesting part is the building
of the time cards, I think!  And not necessarily the querying part.

Parsing, again, can be done by stripping the lines of spaces and using
`words` and `readMaybe`s.  We can use `packFinite :: Integer -> Maybe (Finite
n)` to get our hours and minutes into the `Finite` type that `T` expects.

```haskell
parseLine :: String -> Maybe (Time, Action)
parseLine str = do
    [y,mo,d,h,mi] <- traverse readMaybe timeStamp
    t             <- T y mo d <$> packFinite h <*> packFinite mi
    a             <- case rest of
      "falls":"asleep":_ -> Just ASleep
      "wakes":"up":_     -> Just AWake
      "Guard":n:_        -> AShift . G <$> readMaybe n
      _                  -> Nothing
    pure (t, a)
  where
    (timeStamp, rest) = splitAt 5
                      . words
                      . clearOut (not . isAlphaNum)
                      $ str
```


### Day 4 Benchmarks

```
>> Day 04a
benchmarking...
time                 14.35 ms   (13.79 ms .. 15.27 ms)
                     0.988 R²   (0.975 R² .. 0.998 R²)
mean                 14.96 ms   (14.60 ms .. 15.80 ms)
std dev              1.228 ms   (809.0 μs .. 1.819 ms)
variance introduced by outliers: 39% (moderately inflated)

>> Day 04b
benchmarking...
time                 14.40 ms   (13.12 ms .. 16.95 ms)
                     0.774 R²   (0.585 R² .. 0.988 R²)
mean                 14.59 ms   (13.68 ms .. 18.46 ms)
std dev              3.863 ms   (1.161 ms .. 7.851 ms)
variance introduced by outliers: 87% (severely inflated)
```



Day 5
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day05.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d05p]* / *[Code][d05g]* / *[Rendered][d05h]*

[d05p]: https://adventofcode.com/2018/day/5
[d05g]: https://github.com/mstksg/advent-of-code-2018/blob/master/src/AOC/Challenge/Day05.hs
[d05h]: https://mstksg.github.io/advent-of-code-2018/src/AOC.Challenge.Day05.html

**My write-up for this is actually [on my blog, here][d05b]!**  It involves my
group theory/free group/group homomorphism based solution.  That's my main
reflection, but I also had a method that I wrote *before*, that I would still
like to preserve.

So, preserved here was my original solution involving `funkcyCons` and `foldr`:

One of the first higher-order functions you learn about in Haskill is `foldr`,
which is like a "skeleton transformation" of a list.

That's because in Haskell, a (linked) list is one of two constructors: nil
(`[]`) or cons (`:`).  The list `[1,2,3]` is really `1:(2:(3:[]))`.

`foldr f z` is a function that takes a list replaces all `:`s with `f`, and
`[]`s with `z`s:

```haskell
          [1,2,3] = 1  :  (2  :  (3  :  []))
foldr f z [1,2,3] = 1 `f` (2 `f` (3 `f` z ))
```

This leads to one of the most famous identities in Haskell: `foldr (:) [] xs =
xs`.  That's because if we go in and replace all `(:)`s with `(:)`, and replace
all `[]`s with `[]`... we get back the original list!

But something we can also do is give `foldr` a "custom cons".  A custom cons
that will go in place of the normal cons.

This problem is well-suited for such a custom cons: instead of normal `(:)`,
we'll write a custom cons that respects the rules of reaction: we can't have
two "anti-letters" next to each other:

```haskell
anti :: Char -> Char -> Bool
anti x y = toLower x == toLower y && x /= y

funkyCons :: Char -> String -> String
x `funkyCons` (y:xs)
    | anti x y  = xs
    | otherwise = x:y:xs
x `funkyCons` []     = [x]
```

So, `foldr funkyCons []` will go through a list and replace all `(:)` (cons)
with `funkyCons`, which will "bubble up" the reaction.

So, that's just the entire part 1!

```haskell
day05a :: String -> Int
day05a = length . foldr funkyCons []
```

For part 2 we can just find the minimum length after trying out every
character.

```haskell
day05b :: String -> Int
day05b xs = minimum [ length $ foldr funkyCons [] (remove c xs)
                    | c <- ['a' .. 'z']
                    ]
  where
    remove c = filter ((/= c) . toLower)
```

(Note that in the actual input, there is a trailing newline, so in practice we
have to strip it from the input.)


### Day 5 Benchmarks

```
>> Day 05a
benchmarking...
time                 19.17 ms   (18.71 ms .. 19.63 ms)
                     0.997 R²   (0.994 R² .. 0.999 R²)
mean                 19.36 ms   (19.09 ms .. 19.77 ms)
std dev              831.6 μs   (621.9 μs .. 1.205 ms)
variance introduced by outliers: 13% (moderately inflated)

>> Day 05b
benchmarking...
time                 83.90 ms   (81.79 ms .. 90.30 ms)
                     0.996 R²   (0.989 R² .. 1.000 R²)
mean                 85.52 ms   (84.41 ms .. 87.60 ms)
std dev              2.376 ms   (1.389 ms .. 3.438 ms)
```



Day 6
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day06.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d06p]* / *[Code][d06g]* / *[Rendered][d06h]*

[d06p]: https://adventofcode.com/2018/day/6
[d06g]: https://github.com/mstksg/advent-of-code-2018/blob/master/src/AOC/Challenge/Day06.hs
[d06h]: https://mstksg.github.io/advent-of-code-2018/src/AOC.Challenge.Day06.html

Day 6 Part 1 has us build a [Voronoi Diagram][], and inspect properties of it.
Again, it's all very functional already, since we just need, basically:

1.  A function to get a voronoi diagram from a set of points
2.  A function to query the diagram for properties we care about

[Voronoi Diagram]: https://en.wikipedia.org/wiki/Voronoi_diagram

Along the way, types will help us write our programs, because we constantly
will be asking the compiler for "what could go here" sort of things; it'll also
prevent us from putting the wrong pieces together!

We're going to leverage the *[linear][]* library again, for its `V2 Int` type
for our points.  It has a very useful `Num` and `Foldable` instance, which we
can use to write our `distance` function:

```haskell
type Point = V2 Int

distance :: Point -> Point -> Int
distance x y = sum $ abs (x - y)
```

We're going to be representing our voronoi diagram using a `Map Point Point`: a
map of points to the location of the "Site" they are assigned to.

We can generate such a map by getting a `Set Point` (a set of all points within
our area of interest) and using `M.fromSet :: (Point -> Point) -> Set Point ->
Map Point Point`, to assign a Site to each point.

First, we build a bounding box so don't need to generate an infinite map.  The
`boundingBox` function will take a non-empty list of points (from
`Data.List.NonEmpty`) and return a `V2 Point`, which the lower-left and
upper-right corners of our bounding box.

We need to iterate through the whole list and accumulate the minimum and
maximums of x and y.  We can do it all in one pass by taking advantage of the
`(Semigroup a, Semigroup b) => Semigroup (a, b)` instance, the `Min` and `Max`
newtype wrappers to give us the appropriate semigroups, and using `foldMap1 ::
Semigroup m => (a -> m) -> NonEmpty a -> m`:

```haskell
import           Data.List.NonEmpty (NonEmpty(..))
import           Data.Semigroup.Foldable

type Box = V2 Point

boundingBox :: NonEmpty Point -> Box
boundingBox ps = V2 xMin yMin `V2` V2 xMax yMax
  where
    (Min xMin, Min yMin, Max xMax, Max yMax) = flip foldMap1 ps $ \(V2 x y) ->
        (Min x, Min y, Max x, Max y)
```

(Note that we can just use `foldMap`, because `Min` and `Max` have a `Monoid`
instance because `Int` is bounded.  But that's no fun!  And besides, what if we
had used `Integer`?)

(Also note that this could potentially blow up the stack, because tuples in
Haskell are lazy.  If we cared about performance, we'd use a strict tuple type
instead of the lazy tuple.  In this case, since we only have on the order of a
few thousand points, it's not a huge deal)

Next, we write a function that, given a non-empty set of sites and a point we
wish to label, return the label (site location) of that point.

We do this by making a `NonEmpty (Point, Int)` `dists` that  pair up sites to
the distance between that site and the point.

We need now to find the *minimum* distance in that `NonEmpty`.  But not only
that, we need to find the *unique* minimum, or return `Nothing` if we don't
have a unique minimum.

To do this, we can use `NE.head . NE.groupWith1 snd . NE.sortWith snd`.  This
will sort the `NonEmpty` on the second item (the distance `Int`), which puts
all of the minimal distances in the front.  `NE.groupWith1 snd` will then group
together the pairs with matching distances, moving all of the minimal distance
to the first item in the list.  Then we use the total `NE.head` to get the
first item: the non-empty list with the minimal distances.

Then we can pattern match on `(closestSite, minDist) :| []` to prove that this
"first list" has exactly one item, so the minimum is unique.

```haskell
labelVoronoi
    :: NonEmpty Point     -- ^ set of sites
    -> Point              -- ^ point to label
    -> Maybe Point        -- ^ the label, if unique
labelVoronoi sites p = do
    (closestSite, _) :| [] <- Just
                            . NE.head
                            . NE.groupWith1 snd
                            . NE.sortWith snd
                            $ dists
    pure closestSite
  where
    dists                  = sites <&> \site -> (site, distance p site)
```

Once we have our voronoi diagram `Map Point Point` (map of points to
nearest-site locations), we can use our `freqs :: [Point] -> Map Point Int` function
that we've used many times to get a `Map Point Int`, or a map from Site points to
Frequencies --- essentially a map of Sites to the total area of the cells
assigned to them.  The problem asks us what the size of the largest cell is, so
that's the same as asking for the largest frequency, `maximum`.

```haskell
queryVoronoi :: Map Point Point -> Int
queryVeronoi = maximum . freqs . M.elems
```

One caveat: we need to ignore cells that are "infinite".
To that we can create the set of all Sitse that touch the border, and then
filter out all points in the map that are associated with a Site that touches
the border.

```haskell
cleanVoronoi :: Box -> Map Point Point -> Map Point Point
cleanVoronoi (V2 (V2 xMin yMin) (V2 xMax yMax)) voronoi =
                  M.filter (`S.notMember` edges) voronoi
  where
    edges = S.fromList
          . mapMaybe (\(point, site) -> site <$ guard (onEdge point))
          . M.toList
          $ voronoi
    onEdge (V2 x y) = or [ x == xMin, x == xMax, y == yMin, y == yMax ]
```

We turn `edges` into a `Set` (instead of just a list) because of the fast
`S.notMember` function, to check if a Site ID is in the set of edge-touching
ID's.


Finally, we need to get a function from a bounding box `Box` to `[Point]`: all
of the points in that bounding box.  Luckily, this is exactly what the `Ix`
instance of `V2 Int` gets us:

```haskell
import qualified Data.Ix as Ix

bbPoints :: Box -> [Point]
bbPoints (V2 mins maxs) = Ix.range (mins, maxs)
```

And so Part 1 is:

```haskell
day06a :: NonEmpty Point -> Int
day06a sites = queryVoronoi cleaned
  where
    bb      = boundingBox sites
    voronoi = catMaybes
            . M.fromSet (labelVoronoi sites)
            . S.fromList
            $ bbPoints bb
    cleaned = cleanVoronoi bb voronoi
```

Basically, a series of somewhat complex queries (translated straight from the
prompt) on a voronoi diagram generated by a set of points.

Part 2 is much simpler; it's just filtering for all the points that have a
given function, and then counting how many points there are.

```haskell
day06b :: NonEmpty Point -> Int
day06b sites = length
             . filter ((< 10000) . totalDist)
             . bbPoints
             . boundingBox
             $ sites
  where
    totalDist p = sum $ distance p <$> sites
```

1.  Get the bounding box with `boundingBox`
2.  Generate all of the points in that bounding box with `bbPoints`
3.  Filter those points for just those where their `totalDist` is less than
    10000
4.  Find the number of such points

Another situation where the Part 2 is much simpler than Part 1 :)

Our parser isn't too complicated; it's similar to the parsers from the previous
parts:

```haskell
parseLine :: String -> Maybe Point
parseLine = (packUp =<<)
          . traverse readMaybe
          . words
          . clearOut (not . isDigit)
  where
    packUp [x,y] = Just $ V2 x y
    packUp _     = Nothing
```


### Day 6 Benchmarks

```
>> Day 06a
benchmarking...
time                 308.2 ms   (263.4 ms .. 354.3 ms)
                     0.992 R²   (0.958 R² .. 1.000 R²)
mean                 322.7 ms   (304.4 ms .. 335.7 ms)
std dev              19.37 ms   (10.26 ms .. 25.96 ms)
variance introduced by outliers: 17% (moderately inflated)

* parsing and formatting times excluded

>> Day 06b
benchmarking...
time                 99.82 ms   (94.04 ms .. 106.8 ms)
                     0.991 R²   (0.968 R² .. 1.000 R²)
mean                 93.48 ms   (87.76 ms .. 98.76 ms)
std dev              8.725 ms   (5.895 ms .. 12.41 ms)
variance introduced by outliers: 31% (moderately inflated)

* parsing and formatting times excluded
```



Day 7
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day07.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d07p]* / *[Code][d07g]* / *[Rendered][d07h]*

[d07p]: https://adventofcode.com/2018/day/7
[d07g]: https://github.com/mstksg/advent-of-code-2018/blob/master/src/AOC/Challenge/Day07.hs
[d07h]: https://mstksg.github.io/advent-of-code-2018/src/AOC.Challenge.Day07.html

*Reflection not yet written -- please check back later!*

### Day 7 Benchmarks

```
>> Day 07a
benchmarking...
time                 54.32 μs   (52.04 μs .. 56.39 μs)
                     0.989 R²   (0.981 R² .. 0.995 R²)
mean                 57.04 μs   (55.37 μs .. 59.50 μs)
std dev              6.380 μs   (4.063 μs .. 8.691 μs)
variance introduced by outliers: 86% (severely inflated)

* parsing and formatting times excluded

>> Day 07b
benchmarking...
time                 75.02 μs   (72.17 μs .. 78.17 μs)
                     0.988 R²   (0.984 R² .. 0.994 R²)
mean                 77.93 μs   (75.68 μs .. 79.98 μs)
std dev              6.997 μs   (5.347 μs .. 9.081 μs)
variance introduced by outliers: 79% (severely inflated)

* parsing and formatting times excluded
```



Day 8
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day08.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d08p]* / *[Code][d08g]* / *[Rendered][d08h]*

[d08p]: https://adventofcode.com/2018/day/8
[d08g]: https://github.com/mstksg/advent-of-code-2018/blob/master/src/AOC/Challenge/Day08.hs
[d08h]: https://mstksg.github.io/advent-of-code-2018/src/AOC.Challenge.Day08.html

Another nice one for Haskell!  We're just parsing a stream of `Int`s here :)

```haskell
import qualified Text.Parsec    as P

type Parser = P.Parsec [Int] ()
```

with a `Parsec [Int] ()`, it means that our "tokens" are `Int`.  That means
`P.anyToken :: Parser Int` will pop the next `Int` from the stream.

Our Day 1 will be the `sum1`, which will parse a stream of `Int`s into the sum
of all the metadatas.

```haskell
sum1 :: Parser Int
sum1 = do
    numChild <- P.anyToken
    numMeta  <- P.anyToken
    childs   <- sum <$> replicateM numChild sum1
    metas    <- sum <$> replicateM numMeta  P.anyToken
    pure $ childs + metas
```

And so part 1 is:

```haskell
day01a :: [Int] -> Int
day01a xs = fromRight 0 . P.parse sum1 ""
```

Part 2 is similar.  Again, we parse a stream of ints into a sum:

```
sum2 :: Parser Int
sum2 = do
    numChild <- P.anyToken
    numMeta  <- P.anyToken
    childs   <- replicateM numChild sum2
    metas    <- replicateM numMeta  P.anyToken
    pure $ if null childs
      then sum metas
      else sum . mapMaybe (\i -> childs ^? ix (i - 1)) $ metas
```

I'm using `xs ^? ix i` (from lens) as a "safe indexing", that returns `Maybe
a`.  We need to remember to index into `i - 1` because our indexing starts at
one!

And so part 2 is:

```haskell
day02a :: [Int] -> Int
day02a = fromRight 0 . P.parse sum1 ""
```

We can get a list of `[Int]` from a string input using `map read . words`.


### Day 8 Benchmarks

```
>> Day 08a
benchmarking...
time                 4.896 ms   (4.671 ms .. 5.189 ms)
                     0.985 R²   (0.976 R² .. 0.999 R²)
mean                 4.742 ms   (4.664 ms .. 4.887 ms)
std dev              296.9 μs   (147.8 μs .. 467.3 μs)
variance introduced by outliers: 38% (moderately inflated)

* parsing and formatting times excluded

>> Day 08b
benchmarking...
time                 1.861 ms   (1.821 ms .. 1.900 ms)
                     0.995 R²   (0.993 R² .. 0.997 R²)
mean                 1.846 ms   (1.817 ms .. 1.898 ms)
std dev              131.9 μs   (89.68 μs .. 219.3 μs)
variance introduced by outliers: 53% (severely inflated)

* parsing and formatting times excluded
```



Day 9
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day09.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d09p]* / *[Code][d09g]* / *[Rendered][d09h]*

[d09p]: https://adventofcode.com/2018/day/9
[d09g]: https://github.com/mstksg/advent-of-code-2018/blob/master/src/AOC/Challenge/Day09.hs
[d09h]: https://mstksg.github.io/advent-of-code-2018/src/AOC.Challenge.Day09.html

And today features the re-introduction of an Advent of Code staple: the
(circular) tape/zipper!  I used this data structure last year for days 5, 17,
18 and 23, and I consider them near and dear to my heart as Advent of Code data
structures :)

Last year, I wrote my own implementations on the spot, but since then I've come
to appreciate the *[pointed-list][]* library.  A circular tape is a circular
data structure with a "focus" that you can move back and forth in.  This is
the data structure that implements exactly what the challenge talks about!
It's linear-time on "moving the focus", and constant-time on insertions and
deletions.

[pointed-list]: https://hackage.haskell.org/package/pointedlist

The center of everything is the `place` function, which takes a number to place
and a tape to place it in, and returns an updated tape with the "score"
accumulated for that round.

We see that it is mostly a straightforward translation of the problem
statement.  If `x` is a multiple of 23, then we move 7 spaces to the left, and
return the resulting tape with the item deleted.  The score is the deleted item
plus `x`.  Otherwise, we just move 2 spaces to the right and insert `x`, with a
score of 0.

```haskell
place
    :: Int                       -- ^ number to place
    -> PointedList Int           -- ^ tape
    -> (Int, PointedList Int)    -- ^ resulting tape, and scored points
place x l
    | x `mod` 23 == 0
    = let l'       = PL.moveN (-7) l
          toAdd    = _focus l'
      in  (toAdd + x, fromJust (PL.deleteRight l'))
    | otherwise
    = (0, (PL.insertLeft x . PL.moveN 2) l)
```

We wrap it all up with a `run` function, which is a strict fold over a list of
`(currentPlayer, itemToPlace)` pairs, accumulating a `(scorecard, tape)` state
(our scorecard will be a vector where each index is a different player's
score). At each step, we `place`, and use the result to update our scorecard
and tape. The *lens* library offers some nice tool for incrementing a given
index of a vector.

```haskell
run
    :: Int                  -- ^ number of players
    -> Int                  -- ^ Max # of piece
    -> V.Vector Int
run numPlayers maxPiece = fst
                        . foldl' go (V.replicate numPlayers 0, PL.singleton 0)
                        $ zip players toInsert
  where
    go (!scores, !tp) (!player, !x) = (scores & ix player +~ pts, tp')
      where
        (pts, tp') = place x tp
    players  = (`mod` numPlayers) <$> [0 ..]
    toInsert = [1..maxPiece]
```

And that's it!  The answer is just the maximal score in the final score vector:

```haskell
day09a :: Int -> Int -> Int
day09a numPlayers maxPiece = V.maximum (run numPlayers maxPiece)

day09b :: Int -> Int -> Int
day09b numPlayers maxPiece = V.maximum (run numPlayers (maxPiece * 100))
```

From this naive implementation, Part 1 takes 56.ms, and Part 2 takes 4.5s.


### Day 9 Benchmarks

```
>> Day 09a
benchmarking...
time                 47.19 ms   (45.15 ms .. 48.84 ms)
                     0.994 R²   (0.984 R² .. 0.999 R²)
mean                 47.45 ms   (46.40 ms .. 48.65 ms)
std dev              2.096 ms   (1.673 ms .. 2.757 ms)
variance introduced by outliers: 13% (moderately inflated)

* parsing and formatting times excluded

>> Day 09b
benchmarking...
time                 4.496 s    (4.244 s .. NaN s)
                     0.999 R²   (0.998 R² .. 1.000 R²)
mean                 4.759 s    (4.636 s .. 4.882 s)
std dev              144.1 ms   (118.0 ms .. 166.1 ms)
variance introduced by outliers: 19% (moderately inflated)

* parsing and formatting times excluded
```



Day 10
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day10.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d10p]* / *[Code][d10g]* / *[Rendered][d10h]*

[d10p]: https://adventofcode.com/2018/day/10
[d10g]: https://github.com/mstksg/advent-of-code-2018/blob/master/src/AOC/Challenge/Day10.hs
[d10h]: https://mstksg.github.io/advent-of-code-2018/src/AOC.Challenge.Day10.html

I originally did this by running a simulation, parting the velocity and points
into two lists and using `zipWith (+)` for the simulation.  However, I found a
much nicer closed-form version that [I wrote about in my blog][d10b]!


### Day 10 Benchmarks

```
>> Day 10a
benchmarking...
time                 88.40 μs   (84.73 μs .. 92.44 μs)
                     0.989 R²   (0.982 R² .. 0.996 R²)
mean                 86.33 μs   (83.73 μs .. 89.41 μs)
std dev              8.788 μs   (7.142 μs .. 12.24 μs)
variance introduced by outliers: 82% (severely inflated)

* parsing and formatting times excluded

>> Day 10b
benchmarking...
time                 31.82 μs   (30.15 μs .. 33.56 μs)
                     0.980 R²   (0.974 R² .. 0.990 R²)
mean                 33.74 μs   (32.60 μs .. 34.83 μs)
std dev              4.172 μs   (3.601 μs .. 4.802 μs)
variance introduced by outliers: 89% (severely inflated)

* parsing and formatting times excluded
```



Day 11
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day11.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d11p]* / *[Code][d11g]* / *[Rendered][d11h]*

[d11p]: https://adventofcode.com/2018/day/11
[d11g]: https://github.com/mstksg/advent-of-code-2018/blob/master/src/AOC/Challenge/Day11.hs
[d11h]: https://mstksg.github.io/advent-of-code-2018/src/AOC.Challenge.Day11.html

Day 11 is a nice opportunity to demonstrate dynamic programming in a purely
functional language like Haskell.

Once we define a function to get a power level based on a serial number:

```haskell
type Point = V2 Int

powerLevel :: Int -> Point -> Int
powerLevel sid (V2 x y) = hun ((rid * y + sid) * rid) - 5
  where
    hun = (`mod` 10) . (`div` 100)
    rid = x + 10
```

We can create a `Map` of of `Point` to power level, by creating the set of all
points (using `range` from *Data.Ix*) and using `M.fromSet` with a function.

```haskell
mkMap :: Int -> Map Point Int
mkMap i = M.fromSet (powerLevel i)
        . S.fromList
        $ range (V2 1 1, V2 300 300)
```

Now, both Part 1 and Part 2 involve finding sums of contiguous squares in the
input.  One popular way to do this quickly for many different sums is to build
a [summed-area table][]

```haskell
summedAreaTable :: Map Point Int -> Map Point Int
summedAreaTable mp = force sat
  where
    sat = M.mapWithKey go mp
    go p0 v = (+ v) . sum . catMaybes $
      [ negate <$> M.lookup (p0 - V2 1 1) sat
      ,            M.lookup (p0 - V2 1 0) sat
      ,            M.lookup (p0 - V2 0 1) sat
      ]
```

This is where the dynamic programming happens: our summed area is `sat`, and we
define `sat` in a self-recursive way, using `M.mapWithKey go`.  `M.mapWithKey
go` lazily generates each cell of `sat` by *referring to other cells in `sat`*.
Because of laziness, `mapWithKey` doesn't do any actual "mapping"; but, rather,
allocates thunks at each value in the map.  As soon as these thunks are asked
for, they resolve and are kept as resolved values.

For example, note that `go (V2 1 1) v11` does not refer to any other value.  So,
the map at `V2 1 1` is just `v11`.

However, `go (V2 2 1) v21` depends on one other value: `M.lookup (V2 1 1) sat`.
But, because we already have evaluated this to `v11`, all is well; our answer
is `v21 + v11`.

Now, `go (V2 2 2) v22` depends on three other values: it depends on `M.lookup (V
1 1) sat`, `M.lookup (V2 1 2) sat`, and `M.lookup (V2 1 2) sat`.  GHC will go
and evaluate the ones it needs to evaluate, caching them in the values of the
map, and then just now return the pre-evaluated results.

In this way, we build the summed area table "lazily" in a self-recursive way.
At the end of it all, we return `force sat`, which makes sure the entire `sat`
map is filled out all the way (getting rid of all thunks) when the user
actually tries to *use* the summed area table.

The rest of this involves just making a list of all possible sums of squares,
and finding the maximum of all of them.  Because all of our sums of squares are
now calculable in O(1) on the size of the square (after we generate our
table), the search is very manageable.

```haskell
fromSAT :: Map Point Int -> Point -> Int -> Int
fromSAT sat (subtract (V2 1 1)->p) n = sum . catMaybes $
    [            M.lookup p            sat
    ,            M.lookup (p + V2 n n) sat
    , negate <$> M.lookup (p + V2 0 n) sat
    , negate <$> M.lookup (p + V2 n 0) sat
    ]

findMaxAny :: Map Point Int -> (Point, Int)
findMaxAny mp = fst . maximumBy (comparing snd)
             $ [ ((p, n), fromSAT sat p n)
               , n <- [1 .. 300]
               , p <- range (V2 1 1, V2 (300 - n + 1) (300 - n + 1))
               ]
  where
    sat = summedAreaTable mp
```

Note the benchmarks below are actually using an early-cut-off version of
`findMaxAny` that I implemented after thinking about ways of optimization.


### Day 11 Benchmarks

```
>> Day 11a
benchmarking...
time                 78.61 ms   (76.98 ms .. 80.12 ms)
                     0.999 R²   (0.999 R² .. 1.000 R²)
mean                 78.82 ms   (77.54 ms .. 79.78 ms)
std dev              2.017 ms   (1.127 ms .. 3.346 ms)

* parsing and formatting times excluded

>> Day 11b
benchmarking...
time                 755.1 ms   (625.6 ms .. 855.8 ms)
                     0.995 R²   (0.994 R² .. 1.000 R²)
mean                 856.4 ms   (805.0 ms .. 891.7 ms)
std dev              50.02 ms   (17.43 ms .. 66.73 ms)
variance introduced by outliers: 19% (moderately inflated)

* parsing and formatting times excluded
```



Day 12
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day12.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d12p]* / *[Code][d12g]* / *[Rendered][d12h]*

[d12p]: https://adventofcode.com/2018/day/12
[d12g]: https://github.com/mstksg/advent-of-code-2018/blob/master/src/AOC/Challenge/Day12.hs
[d12h]: https://mstksg.github.io/advent-of-code-2018/src/AOC.Challenge.Day12.html

Day 12 is made a little more fun with everyone's favorite Haskell data
structures: maps and sets! (Note that I've pretty much used Maps and Sets for
every challenge, more or less!)

We can represent a "context", or neighborhood, as a `Set (Finite 5)`, where
`Finite 5` can be thought of as a type that only contains the numbers 0, 1, 2,
3, and 4 (five elements only).  We'll treat 0 as "two to the left", 1 as "one
to the left", 2 as "the current point", 3 as "one to the right", and 4 as "two
to the right".  The set will *contain* the given finite if it is "on" in that
position.  So, for example, the context `#.##.` would be `S.fromList [0,2,3]`.

```haskell
type Ctx = Set (Finite 5)
```

Our ruleset will be `Set Ctx`, or a set of neighborhoods.  If a given
neighborhood is *in* the set, then that means that the plant is meant to turn
on.  Otherwise, it means that the plant is meant to turn off.  So, `#.##. => #`
would mean that the item `S.fromList [0,2,3]` is in the ruleset, but `##..# =>
.` would mean that the item `S.fromList [0,1,4]` is *not* in the ruleset.

Finally, the type of our "world" is just `Set Int`.  If a plant is "on", then
its index will be in the set.  Otherwise, its index will *not* be in the set.

One nice thing about representing the world as `Set Int` is that getting the
"sum of all plant IDs that are on" is just `sum :: Set Int -> Int` :)

Writing our step function is going to be filtering all of the "candidate"
positions for the ones that remain "on".  That's it!  We perform this filter by
aggregating the neighborhood around each point and checking if the neighborhood
is in the ruleset.

```haskell
step
    :: Set Ctx
    -> Set Int
    -> Set Int
step ctxs w0 = S.fromDistinctAscList
             . filter go
             $ [S.findMin w0 - 2 .. S.findMax w0 + 2]
  where
    go i = neighbs `S.member` ctxs
      where
        neighbs = S.fromDistinctAscList . flip filter finites $ \j ->
          (i - 2 + fromIntegral j) `S.member` w0
```

Part 2 requires a bit of trickery.  If we monitor our outputs, we can observe
that the entire shape of the world starts to loop after a given amount of time.
We can find this loop structure by stepping repeatedly and finding the first
item that is repeated, by using a "seen items" set.  We have to make sure to
"normalize" our representation so that the same shame will be matched no matter
what coordinate it starts at.  I did this by subtracting out the minimum item
in the set, so that the leftmost plant is always at zero.

```haskell
findLoop
    :: Set Ctx
    -> Set Pos
    -> (Int, Int, Int)      -- time to loop, loop size, loop incr
findLoop ctxs w0 = go (M.singleton w0 (0, 0)) 1 w0
  where
    go !seen !i !w = case M.lookup w'Norm seen of
        Nothing              -> go (M.insert w'Norm (mn, i) seen) (i + 1) w'
        Just (seenMn, seenI) -> (seenI, i - seenI, mn - seenMn)
      where
        w'           = step ctxs w
        (mn, w'Norm) = normalize w'
    normalize w = (mn, S.map (subtract mn) w)
      where
        mn = S.findMin w
```

And now we can be a little clever using `divMod` to factor out 50 billion into
the "initialization", the "loop amount", and the "amount to increase":

```haskell
stepN
    :: Int
    -> Set Pos
    -> Set Ctx
    -> Set Pos
stepN n w ctx = goN extra
              . S.map (+ (loopIncr * looped))
              . goN ttl
              $ w
  where
    goN m = (!!! m) . iterate (step ctx)
    (ttl, loopSize, loopIncr) = findLoop ctx w
    (looped, extra) = (n - ttl) `divMod` loopSize
```


### Day 12 Benchmarks

```
>> Day 12a
benchmarking...
time                 1.008 ms   (987.2 μs .. 1.023 ms)
                     0.994 R²   (0.990 R² .. 0.998 R²)
mean                 989.1 μs   (971.1 μs .. 1.006 ms)
std dev              64.14 μs   (44.54 μs .. 84.12 μs)
variance introduced by outliers: 53% (severely inflated)

* parsing and formatting times excluded

>> Day 12b
benchmarking...
time                 22.88 ms   (22.68 ms .. 23.12 ms)
                     1.000 R²   (0.999 R² .. 1.000 R²)
mean                 22.89 ms   (22.78 ms .. 23.10 ms)
std dev              305.3 μs   (189.3 μs .. 471.2 μs)

* parsing and formatting times excluded
```



Day 13
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day13.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d13p]* / *[Code][d13g]* / *[Rendered][d13h]*

[d13p]: https://adventofcode.com/2018/day/13
[d13g]: https://github.com/mstksg/advent-of-code-2018/blob/master/src/AOC/Challenge/Day13.hs
[d13h]: https://mstksg.github.io/advent-of-code-2018/src/AOC.Challenge.Day13.html

Day 13 is fun because it can be stated in terms of a *[hylomorphism][]*!

[hylomorphism]: https://en.wikipedia.org/wiki/Hylomorphism_(computer_science)

First, our data types:

```haskell
type Point = V2 Int

data Turn = TurnNW      -- ^ a forward-slash mirror @/@
          | TurnNE      -- ^ a backwards-slash mirror @\\@
          | TurnInter   -- ^ a four-way intersection
  deriving (Eq, Show, Ord)

data Dir = DN | DE | DS | DW
  deriving (Eq, Show, Ord, Enum, Bounded)

data Cart = C { _cDir   :: Dir
              , _cTurns :: Int
              }
  deriving (Eq, Show)

makeLenses ''Cart

newtype ScanPoint = SP { _getSP :: Point }
  deriving (Eq, Show, Num)

instance Ord ScanPoint where
    compare = comparing (view _y . _getSP)
           <> comparing (view _x . _getSP)

type World = Map Point     Turn
type Carts = Map ScanPoint Cart
```

We will be using `Map ScanPoint Cart` as our priority queue; `ScanPoint`
newtype-wraps a `Point` in a way that its `Ord` instance will give us the
lowest `y` first, *then* the lowest `x` to break ties.

Note that we don't ever have to store any of the "track" positions, `|` or `-`.
That's because they don't affect the carts in any way.

Next, we can implement the actual logic of moving a single `Cart`:

```haskell
stepCart :: World -> ScanPoint -> Cart -> (ScanPoint, Cart)
stepCart w (SP p) c = (SP p', maybe id turner (M.lookup p' w) c)
  where
    p' = p + case c ^. cDir of
      DN -> V2 0    (-1)
      DE -> V2 1    0
      DS -> V2 0    1
      DW -> V2 (-1) 0
    turner = \case
      TurnNW    -> over cDir $ \case DN -> DE; DE -> DN; DS -> DW; DW -> DS
      TurnNE    -> over cDir $ \case DN -> DW; DW -> DN; DS -> DE; DE -> DS
      TurnInter -> over cTurns (+ 1) . over cDir (turnWith (c ^. cTurns))
    turnWith i = case i `mod` 3 of
      0 -> turnLeft
      1 -> id
      _ -> turnLeft . turnLeft . turnLeft
    turnLeft DN = DW
    turnLeft DE = DN
    turnLeft DS = DE
    turnLeft DW = DS
```

There are ways we can the turning and `Dir` manipulations, but this way already
is pretty clean, I think!  We use lens combinators like `over` to simplify our
updating of carts.  If there is no turn at a given coordinate, then the cart
just stays the same, and only the position updates.

Now, to separate out the *running* of the simulation from the *consumption* of
the results, we can make a type that emits the result of a single step in the
world:

```haskell
data CartLog a = CLCrash Point a      -- ^ A crash, at a given point
               | CLTick        a      -- ^ No crashes, just a normal timestep
               | CLDone  Point        -- ^ Only one car left, at a given point
  deriving (Show, Functor)
```

And we can use that to implement `stepCarts`, which takes a "waiting, done"
queue of carts and:

1.  If `waiting` is empty, we dump `done` back into `waiting` and emit `CLTick`
    with our updated state.  However, if `done` is empty, then we are done;
    emit `CLDone` with no new state.
2.  Otherwise, pop an cart from `waiting` and move it.  If there is a crash,
    emit `CLCrash` with the updated state (with things deleted).

```haskell
stepCarts
    :: World
    -> (Carts, Carts)
    -> CartLog (Carts, Carts)
stepCarts w (waiting, done) = case M.minViewWithKey waiting of
    Nothing -> case M.minViewWithKey done of
      Just ((SP lastPos, _), M.null->True) -> CLDone lastPos
      _                                    -> CLTick (done, M.empty)
    Just (uncurry (stepCart w) -> (p, c), waiting') ->
      case M.lookup p (waiting' <> done) of
        Nothing -> CLTick             (waiting'           , M.insert p c done)
        Just _  -> CLCrash (_getSP p) (M.delete p waiting', M.delete p done  )
```

Now, we can write our consumers.  These will be fed the results of `stepCarts`
as they are produced.  However, the `a` parameters will actually be the "next
results", in a way:

```haskell
-- | Get the result of the first crash.
firstCrash :: CartLog (Maybe Point) -> Maybe Point
firstCrash (CLCrash p _) = Just p   -- this is it, chief
firstCrash (CLTick    p) = p        -- no, we have to go deeper
firstCrash (CLDone  _  ) = Nothing  -- we reached the end of the line, no crash.

-- | Get the final point.
lastPoint :: CartLog Point -> Point
lastPoint (CLCrash _ p) = p   -- we have to go deeper
lastPoint (CLTick    p) = p   -- even deeper
lastPoint (CLDone  p  ) = p   -- we're here
```

And now:

```haskell
day13a :: World -> Carts -> Maybe Point
day13a w c = (firstCrash `hylo` stepCarts w) (c, M.empty)

day13b :: World -> Carts -> Point
day13b w c = (lastPoint `hylo` stepCarts w) (c, M.empty)
```

The magic of `hylo` is that, as `firstCrash` and `lastPoint` "demand" new
values or points, `hylo` will ask `stepCarts w` for them.  So, `stepCarts w` is
iterated as many times as `firstCrash` and `lastPoint` needs.


### Day 13 Benchmarks

```
>> Day 13a
benchmarking...
time                 14.85 ms   (14.02 ms .. 15.76 ms)
                     0.987 R²   (0.974 R² .. 0.999 R²)
mean                 15.50 ms   (14.86 ms .. 17.41 ms)
std dev              2.581 ms   (580.6 μs .. 5.173 ms)
variance introduced by outliers: 75% (severely inflated)

>> Day 13b
benchmarking...
time                 20.44 ms   (19.71 ms .. 21.10 ms)
                     0.991 R²   (0.977 R² .. 0.998 R²)
mean                 22.90 ms   (21.91 ms .. 24.08 ms)
std dev              2.522 ms   (1.658 ms .. 3.644 ms)
variance introduced by outliers: 48% (moderately inflated)
```



Day 14
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day14.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d14p]* / *[Code][d14g]* / *[Rendered][d14h]*

[d14p]: https://adventofcode.com/2018/day/14
[d14g]: https://github.com/mstksg/advent-of-code-2018/blob/master/src/AOC/Challenge/Day14.hs
[d14h]: https://mstksg.github.io/advent-of-code-2018/src/AOC.Challenge.Day14.html

*Reflection not yet written -- please check back later!*

### Day 14 Benchmarks

```
>> Day 14a
benchmarking...
time                 408.9 μs   (408.2 μs .. 409.9 μs)
                     1.000 R²   (1.000 R² .. 1.000 R²)
mean                 409.9 μs   (409.1 μs .. 411.2 μs)
std dev              2.912 μs   (1.399 μs .. 4.983 μs)

* parsing and formatting times excluded

>> Day 14b
benchmarking...
time                 174.5 ms   (170.8 ms .. 177.2 ms)
                     1.000 R²   (0.999 R² .. 1.000 R²)
mean                 181.1 ms   (178.4 ms .. 184.3 ms)
std dev              4.106 ms   (3.141 ms .. 5.151 ms)
variance introduced by outliers: 14% (moderately inflated)

* parsing and formatting times excluded
```



Day 15
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day15.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d15p]* / *[Code][d15g]* / *[Rendered][d15h]*

[d15p]: https://adventofcode.com/2018/day/15
[d15g]: https://github.com/mstksg/advent-of-code-2018/blob/master/src/AOC/Challenge/Day15.hs
[d15h]: https://mstksg.github.io/advent-of-code-2018/src/AOC.Challenge.Day15.html

This one feels complex at first (a generate-check-generate-check loop)...if you
take a generate-check loop, you also have to be sure to make sure you check the
case of 1 or 2 added digits.

However, it becomes much simpler if you separate the act of generation and
checking as two different things.  Luckily, with Haskell, this is fairly easy
with lazily linked lists.

```haskell
chocolatePractice :: [Int]
chocolatePractice = 3 : 7 : go 0 1 (Seq.fromList [3,7])
  where
    go !p1 !p2 !tp = newDigits ++ go p1' p2' tp'
      where
        sc1 = tp `Seq.index` p1
        sc2 = tp `Seq.index` p2
        newDigits = digitize $ sc1 + sc2
        tp' = tp <> Seq.fromList newDigits
        p1' = (p1 + sc1 + 1) `mod` length tp'
        p2' = (p2 + sc2 + 1) `mod` length tp'

digitize :: Int -> [Int]
digitize ((`divMod` 10)->(x,y))
    | x == 0    = [y]
    | otherwise = [x,y]
```

We use `go` to lazily generate new items as they are demanded.  Once the user
consumes all of the `newDigits` asks for more, `go` will be asked to generate
new digits.  The important thing is that this is demand-driven.

We keep track of the current tape using `Seq` from *Data.Sequence* for its O(1)
appends and O(log) indexing -- the two things we do the most.  We could also
get away with pre-allocation with vectors for amortized O(1) suffix appends and
O(1) indexing, as well.

Note that `chocolatePractice` is effectively the same for every per-user input
data. It's just a (lazily generated) list of all of the chocolate practice digits.

Part 1 then is just a `drop` then a `take`:

```haskell
day14a :: Int -> [Int]
day14a n = take 10 (drop n chocolatePractice)
```

Part 2, we can use `isPrefixOf` from *Data.List* and check every `tails` until
we get one that *does* have our digit list as a prefix:

```haskell
substrLoc :: [Int] -> [Int] -> Maybe Int
substrLoc xs = length
             . takeWhile (not . (xs `isPrefixOf`))
             . tails

day14b :: [Int] -> [Int]
day14b xs = xs `substrLoc` cholcatePractice
```

Note that `chocolatePractice` is essentially just a futumorphism, so this whole
thing can be stated in terms of a chronomorphism.  I don't know if there would
be any advantage in doing so.  But it's interesting to me that I solved Day 13
using a hylomorphism, and now Day 14 using what is essentially a chronomorphism
... so maybe recursion-schemes is the killer app for Advent of Code? :)

A note on benchmarks -- it's very difficult to benchmark Day 14, because I
couldn't get ghc to stop memoizing `chocolatePractice`.  This means my repeated
benchmarks kept on re-using the stored list.

However, using `time`, I timed Part 1 to about 180ms, and Part 2 to 10s.


### Day 15 Benchmarks

```
>> Day 15a
benchmarking...
time                 4.564 s    (4.276 s .. 4.808 s)
                     1.000 R²   (0.998 R² .. 1.000 R²)
mean                 4.560 s    (4.509 s .. 4.630 s)
std dev              68.16 ms   (25.90 ms .. 90.81 ms)
variance introduced by outliers: 19% (moderately inflated)

>> Day 15b
benchmarking...
time                 23.73 s    (23.39 s .. 23.87 s)
                     1.000 R²   (1.000 R² .. 1.000 R²)
mean                 23.66 s    (23.58 s .. 23.71 s)
std dev              75.10 ms   (3.886 ms .. 94.13 ms)
variance introduced by outliers: 19% (moderately inflated)
```



Day 16
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day16.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d16p]* / *[Code][d16g]* / *[Rendered][d16h]*

[d16p]: https://adventofcode.com/2018/day/16
[d16g]: https://github.com/mstksg/advent-of-code-2018/blob/master/src/AOC/Challenge/Day16.hs
[d16h]: https://mstksg.github.io/advent-of-code-2018/src/AOC.Challenge.Day16.html

Today was fun because I got to re-use some techniques I discussed in a blog
post I've written in the past: [Send More Money: List and
StateT][send-more-money].  I talk about using `StateT` over `[]` to do
implement prolog-inspired constraint satisfaction searches while taking
advantage of laziness.

[send-more-money]: https://blog.jle.im/entry/unique-sample-drawing-searches-with-list-and-statet.html

First of all, our types.  I'll be using the *[vector-sized][]* library with
*[finite-typelits][]* to help us do safe indexing.  A `Vector n a` is a vector
of `n` `a`s, and a `Finite n` is a legal index into such a vector.  For
example, a `Vector 4 Int` is a vector of 4 `Int`s, and `Finite 4` is 0, 1, 2,
or 3.

[vector-sized]: https://hackage.haskell.org/package/vector-sized
[finite-typelits]: https://hackage.haskell.org/package/finite-typelits

```haskell
import           Data.Vector.Sized (Vector)
import           Data.Finite       (Finite)

type Reg = Vector 4 Int

data Instr a = I { _iOp  :: a
                 , _iInA :: Finite 4
                 , _iInB :: Finite 4
                 , _iOut :: Finite 4
                 }
  deriving (Show, Functor)

data Trial = T { _tBefore :: Reg
               , _tInstr  :: Instr (Finite 16)
               , _tAfter  :: Reg
               }
  deriving Show

data OpCode = OAddR | OAddI
            | OMulR | OMulI
            | OBanR | OBanI
            | OBorR | OBorI
            | OSetR | OSetI
            | OGtIR | OGtRI | OGtRR
            | OEqIR | OEqRI | OEqRR
  deriving (Show, Eq, Ord, Enum, Bounded)
```

We can leave `Instr` parameterized over the opcode type so that we can use it
with `Finite 16` initially, and `OpCode` later.

We do need to implement the functionality of each op, which we can do by
pattern matching on an `OpCode`.  We use some lens functionality to simplify
some of the editing of indices, but we could also just manually modify indices.

```haskell
runOp :: Instr OpCode -> Reg -> Reg
runOp I{..} = case _iOp of
    OAddR -> \r -> r & V.ix _iOut .~ r ^. V.ix _iInA  +  r ^. V.ix _iInB
    OAddI -> \r -> r & V.ix _iOut .~ r ^. V.ix _iInA  +  fromIntegral _iInB
    OMulR -> \r -> r & V.ix _iOut .~ r ^. V.ix _iInA  *  r ^. V.ix _iInB
    OMulI -> \r -> r & V.ix _iOut .~ r ^. V.ix _iInA  *  fromIntegral _iInB
    OBanR -> \r -> r & V.ix _iOut .~ r ^. V.ix _iInA .&. r ^. V.ix _iInB
    OBanI -> \r -> r & V.ix _iOut .~ r ^. V.ix _iInA .&. fromIntegral _iInB
    OBorR -> \r -> r & V.ix _iOut .~ r ^. V.ix _iInA .|. r ^. V.ix _iInB
    OBorI -> \r -> r & V.ix _iOut .~ r ^. V.ix _iInA .|. fromIntegral _iInB
    OSetR -> \r -> r & V.ix _iOut .~ r ^. V.ix _iInA
    OSetI -> \r -> r & V.ix _iOut .~                     fromIntegral _iInA
    OGtIR -> \r -> r & V.ix _iOut . enum .~ (fromIntegral _iInA  > r ^. V.ix _iInB   )
    OGtRI -> \r -> r & V.ix _iOut . enum .~ (r ^. V.ix _iInA     > fromIntegral _iInB)
    OGtRR -> \r -> r & V.ix _iOut . enum .~ (r ^. V.ix _iInA     > r ^. V.ix _iInB   )
    OEqIR -> \r -> r & V.ix _iOut . enum .~ (fromIntegral _iInA == r ^. V.ix _iInB   )
    OEqRI -> \r -> r & V.ix _iOut . enum .~ (r ^. V.ix _iInA    == fromIntegral _iInB)
    OEqRR -> \r -> r & V.ix _iOut . enum .~ (r ^. V.ix _iInA    == r ^. V.ix _iInB   )
```

Now, from a `Trial`, we can get a set of `OpCode`s that are plausible
candidates if the output matches the expected output for a given `OpCode`, for
the given input.

```haskell
plausible :: Trial -> Set OpCode
plausible T{..} = S.fromList (filter tryTrial [OAddR ..])
  where
    tryTrial :: OpCode -> Bool
    tryTrial o = runOp (_tInstr { _iOp = o }) _tBefore == _tAfter
```

Part 1 is, then, just counting the trials with three or more plausible
candidates:

```haskell
day16a :: [Trial] -> Int
day16a = length . filter ((>= 3) . S.size . plausible)
```

Part 2 is where we can implement our constraint satisfaction search.  Following
[this blog post][send-more-money], we can write a search using `StateT (Set
OpCode) []`.  Our state will be the `OpCode`s that we have already used.  We
fill up a vector step-by-step, by picking only `OpCode`s that have not been
used yet:

```haskell
fillIn :: Set OpCode -> StateT (Set OpCode) [] OpCode
fillIn candidates = do
    unseen <- gets (candidates `S.difference`)  -- filter only unseen candidates
    pick   <- lift $ toList unseen              -- branch on all unseen candidates
    modify $ S.insert pick                      -- in this branch, 'pick' is seen
    pure pick                                   -- return our pick for the branch
```

Now, if we have a map of `Finite 16` (op code numbers) to their candidates (a
`Map (Finite 16) (Set OpCode)`), we can populate all legal
configurations.  We'll use `Vector 16 OpCode` to represent our configuration:
`0` will represent the first item, `1` will represent the second, etc.  We can
use `V.generate :: (Finite n -> m a) -> m (Vector n a)`, and run our `fillIn`
action for every `Finite n`.

```haskell
fillVector
    :: Map (Finite 16) (Set OpCode)
    -> StateT (Set OpCode) [] (Vector 16 OpCode)
fillVector candmap = V.generateM $ \i -> do
    Just cands <- pure $ M.lookup i candmap
    fillIn cands

fromClues
    :: Map (Finite 16) (Set OpCode)
    -> Maybe (Vector 16 OpCode)
fromClues m = listToMaybe $ evalStateT (fillVector m) S.empty
```

If this part is confusing, the [blog post][send-more-money] explains how
`StateT` and `[]`, together, give you this short-circuting search behavior!

So our Part 2 is using `fromClues` from all of the candidates (making sure to
do a set intersection if we get more than one clue for an opcode number), and a
`foldl'` over our instruction list:

```haskell
day16b :: [Trial] -> [Instr (Finite 16)] -> Int
day16b ts = V.head . foldl' step (V.replicate 0)
  where
    candmap    = M.fromListWith S.intersection
               $ [ (_iOp (_tInstr t), plausible t)
                 | t <- ts
                 ]
    Just opMap = fromClues candmap
    step r i = runOp i' r
      where
        i' = (opMap `V.index`) <$> i
```


### Day 16 Benchmarks

```
>> Day 16a
benchmarking...
time                 9.585 ms   (9.225 ms .. 9.969 ms)
                     0.984 R²   (0.968 R² .. 0.996 R²)
mean                 9.555 ms   (9.385 ms .. 9.909 ms)
std dev              624.8 μs   (404.7 μs .. 974.3 μs)
variance introduced by outliers: 34% (moderately inflated)

>> Day 16b
benchmarking...
time                 300.0 ms   (275.3 ms .. 322.4 ms)
                     0.998 R²   (0.995 R² .. 1.000 R²)
mean                 314.2 ms   (305.1 ms .. 323.9 ms)
std dev              12.42 ms   (8.090 ms .. 15.01 ms)
variance introduced by outliers: 16% (moderately inflated)
```



Day 17
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day17.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d17p]* / *[Code][d17g]* / *[Rendered][d17h]*

[d17p]: https://adventofcode.com/2018/day/17
[d17g]: https://github.com/mstksg/advent-of-code-2018/blob/master/src/AOC/Challenge/Day17.hs
[d17h]: https://mstksg.github.io/advent-of-code-2018/src/AOC.Challenge.Day17.html

*Reflection not yet written -- please check back later!*

### Day 17 Benchmarks

```
>> Day 17a
benchmarking...
time                 65.59 ms   (63.36 ms .. 70.63 ms)
                     0.993 R²   (0.978 R² .. 1.000 R²)
mean                 64.28 ms   (63.43 ms .. 66.36 ms)
std dev              2.274 ms   (679.9 μs .. 3.901 ms)

* parsing and formatting times excluded

>> Day 17b
benchmarking...
time                 58.71 ms   (53.74 ms .. 64.70 ms)
                     0.981 R²   (0.963 R² .. 0.999 R²)
mean                 57.38 ms   (55.85 ms .. 60.74 ms)
std dev              4.198 ms   (2.823 ms .. 6.416 ms)
variance introduced by outliers: 23% (moderately inflated)

* parsing and formatting times excluded
```



Day 18
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day18.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d18p]* / *[Code][d18g]* / *[Rendered][d18h]*

[d18p]: https://adventofcode.com/2018/day/18
[d18g]: https://github.com/mstksg/advent-of-code-2018/blob/master/src/AOC/Challenge/Day18.hs
[d18h]: https://mstksg.github.io/advent-of-code-2018/src/AOC.Challenge.Day18.html

*Reflection not yet written -- please check back later!*

### Day 18 Benchmarks

```
>> Day 18a
benchmarking...
time                 34.06 ms   (33.24 ms .. 34.99 ms)
                     0.998 R²   (0.996 R² .. 1.000 R²)
mean                 34.02 ms   (33.54 ms .. 34.33 ms)
std dev              807.0 μs   (587.4 μs .. 1.063 ms)

>> Day 18b
benchmarking...
time                 3.755 s    (3.533 s .. 3.955 s)
                     1.000 R²   (0.998 R² .. 1.000 R²)
mean                 3.732 s    (3.680 s .. 3.778 s)
std dev              62.21 ms   (28.52 ms .. 85.78 ms)
variance introduced by outliers: 19% (moderately inflated)
```



Day 19
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day19.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d19p]* / *[Code][d19g]* / *[Rendered][d19h]*

[d19p]: https://adventofcode.com/2018/day/19
[d19g]: https://github.com/mstksg/advent-of-code-2018/blob/master/src/AOC/Challenge/Day19.hs
[d19h]: https://mstksg.github.io/advent-of-code-2018/src/AOC.Challenge.Day19.html

*Reflection not yet written -- please check back later!*

### Day 19 Benchmarks

```
>> Day 19a
benchmarking...
time                 143.8 ms   (-388.1 ms .. 502.9 ms)
                     0.397 R²   (0.003 R² .. 1.000 R²)
mean                 859.1 ms   (514.4 ms .. 1.207 s)
std dev              441.3 ms   (226.4 ms .. 534.5 ms)
variance introduced by outliers: 74% (severely inflated)

>> Day 19b
benchmarking...
time                 5.586 s    (5.275 s .. NaN s)
                     0.999 R²   (0.997 R² .. 1.000 R²)
mean                 5.685 s    (5.574 s .. 5.775 s)
std dev              129.2 ms   (67.31 ms .. 181.9 ms)
variance introduced by outliers: 19% (moderately inflated)
```



Day 20
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day20.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d20p]* / *[Code][d20g]* / *[Rendered][d20h]*

[d20p]: https://adventofcode.com/2018/day/20
[d20g]: https://github.com/mstksg/advent-of-code-2018/blob/master/src/AOC/Challenge/Day20.hs
[d20h]: https://mstksg.github.io/advent-of-code-2018/src/AOC.Challenge.Day20.html

Like Day 4, this one is made pretty simple with parser combinators! :D

Just for clarity, we will tokenize the stream first -- but it's not strictly
necessary.

```haskell
data Dir = DN | DE | DS | DW
  deriving (Show, Eq, Ord)

data RegTok = RTStart
            | RTDir Dir
            | RTRParen
            | RTOr
            | RTLParen
            | RTEnd
  deriving (Show, Eq, Ord)

parseToks :: String -> [RegTok]
parseToks = mapMaybe $ \case
    '^' -> Just RTStart
    'N' -> Just $ RTDir DN
    'E' -> Just $ RTDir DE
    'W' -> Just $ RTDir DW
    'S' -> Just $ RTDir DS
    '|' -> Just RTOr
    '(' -> Just RTRParen
    ')' -> Just RTLParen
    '$' -> Just RTEnd
    _   -> Nothing
```

Now, to write our parser!  We will parse our `[RegTok]` stream into a set of
edges.

```haskell
import           Linear (V2(..))
import qualified Text.Parsec as P

-- V2 Int = (Int, Int), essentially
type Point = V2 Int

data Edge = E Point Point
  deriving (Show, Eq, Ord)

-- | Make an edge.  Normalizes so we can compare for uniqueness.
mkEdge :: Point -> Point -> Edge
mkEdge x y
  | x <= y    = E x y
  | otherwise = E y x

-- | Parse a stream of `RegTok`.  We have a State of the "current point".
type Parser = P.Parsec [RegTok] Point
```

We either have a "normal step", or a "branching step".  The entire way, we
accumulate a set of all edges.

```haskell
tok :: RegTok -> Parser ()
tok t = P.try $ guard . (== t) =<< P.anyToken

-- | `anySteps` is many normal steps or branch steps.  Each of these gives an
-- edge, so we union all of their edges together.
anySteps :: Parser (Set Edge)
anySteps = fmap S.unions . P.many $
    P.try normalStep P.<|> branchStep

-- | `normalStep` is a normal step without any branching.  It is an `RTDir`
-- token, followed by `anySteps`.  We add the newly discovered edge to the
-- edges in `anySteps`.
normalStep :: Parser (Set Edge)
normalStep = do
    currPos <- P.getState
    RTDir d <- P.anyToken
    let newPos = currPos + case d of
          DN -> V2   0 (-1)
          DE -> V2   1   0
          DS -> V2   0   1
          DW -> V2 (-1)  0
    P.setState newPos
    S.insert (mkEdge currPos newPos) <$> anySteps

-- | `branchStep` is many `anySteps`, each separated by an `RTOr` token.  It is
-- located between `RTRParen` and `RTLParen`.
branchStep :: Parser (Set Edge)
branchStep = (tok RTRParen `P.between` tok RTLParen) $ do
    initPos <- P.getState
    fmap S.unions . (`P.sepBy` tok RTOr) $ do
      P.setState initPos
      anySteps
```

Our final regexp parser is just `anySteps` seperated by the start and end
tokens:

```haskell
buildEdges :: Parser (Set Edge)
buildEdges = (tok RTStart `P.between` tok RTEnd) anySteps
```

Now that we have successfully parsed the "regexp" into a set of edges, we need
to follow all of the edges into all of the rooms.  We can do this using
recursive descent.

```haskell
neighbs :: Point -> [Point]
neighbs p = (p +) <$> [ V2 0 (-1), V2 1 0, V2 0 1, V2 (-1) 0 ]


roomDistances :: Set Edge -> [Int]
roomDistances es = go 0 S.empty (V2 0 0)
  where
    go :: Int -> Set Point -> Point -> [Int]
    go n seen p = (n :) $
        concatMap (go (n + 1) (S.insert p seen)) allNeighbs
      where
        allNeighbs = filter ((`S.member` es) . mkEdge p)
                   . filter (`S.notMember` seen)
                   $ neighbs p
```

We have to make sure to keep track of the "already seen" rooms.  On my first
attempt, I forgot to do this!

Anyway, here's Part 1 and Part 2:

```haskell
day20a :: String -> Int
day20a inp = maximum (roomDistances edges)
  where
    Right edges = P.runParser buildEdges (V2 0 0) ""
                    (parseToks inp)

day20b :: String -> Int
day20b inp = length . filter (>= 1000) $ roomDistances edges
  where
    Right edges = P.runParser buildEdges (V2 0 0) ""
                    (parseToks inp)
```


### Day 20 Benchmarks

```
>> Day 20a
benchmarking...
time                 48.44 ms   (44.77 ms .. 54.27 ms)
                     0.962 R²   (0.880 R² .. 0.999 R²)
mean                 49.75 ms   (47.43 ms .. 53.45 ms)
std dev              5.563 ms   (2.050 ms .. 7.731 ms)
variance introduced by outliers: 44% (moderately inflated)

>> Day 20b
benchmarking...
time                 489.6 ms   (419.0 ms .. 566.6 ms)
                     0.997 R²   (0.989 R² .. 1.000 R²)
mean                 488.4 ms   (478.4 ms .. 499.7 ms)
std dev              13.00 ms   (5.349 ms .. 17.77 ms)
variance introduced by outliers: 19% (moderately inflated)
```



Day 21
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day21.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d21p]* / *[Code][d21g]* / *[Rendered][d21h]*

[d21p]: https://adventofcode.com/2018/day/21
[d21g]: https://github.com/mstksg/advent-of-code-2018/blob/master/src/AOC/Challenge/Day21.hs
[d21h]: https://mstksg.github.io/advent-of-code-2018/src/AOC.Challenge.Day21.html

*Reflection not yet written -- please check back later!*

### Day 21 Benchmarks

```
>> Day 21a
benchmarking...
time                 97.10 μs   (94.80 μs .. 98.83 μs)
                     0.993 R²   (0.989 R² .. 0.996 R²)
mean                 91.40 μs   (88.36 μs .. 93.67 μs)
std dev              9.194 μs   (8.137 μs .. 10.49 μs)
variance introduced by outliers: 82% (severely inflated)

>> Day 21b
benchmarking...
time                 339.6 ms   (252.3 ms .. 400.6 ms)
                     0.993 R²   (0.975 R² .. 1.000 R²)
mean                 356.0 ms   (339.6 ms .. 368.3 ms)
std dev              17.27 ms   (8.134 ms .. 24.03 ms)
variance introduced by outliers: 19% (moderately inflated)
```



Day 22
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day22.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d22p]* / *[Code][d22g]* / *[Rendered][d22h]*

[d22p]: https://adventofcode.com/2018/day/22
[d22g]: https://github.com/mstksg/advent-of-code-2018/blob/master/src/AOC/Challenge/Day22.hs
[d22h]: https://mstksg.github.io/advent-of-code-2018/src/AOC.Challenge.Day22.html

*Reflection not yet written -- please check back later!*

### Day 22 Benchmarks

```
>> Day 22a
benchmarking...
time                 10.27 ms   (10.02 ms .. 10.67 ms)
                     0.972 R²   (0.893 R² .. 1.000 R²)
mean                 10.24 ms   (10.00 ms .. 10.96 ms)
std dev              1.023 ms   (194.4 μs .. 1.888 ms)
variance introduced by outliers: 55% (severely inflated)

* parsing and formatting times excluded

>> Day 22b
benchmarking...
time                 504.5 ms   (384.9 ms .. 592.7 ms)
                     0.994 R²   (0.978 R² .. 1.000 R²)
mean                 497.9 ms   (483.7 ms .. 517.7 ms)
std dev              19.92 ms   (5.322 ms .. 26.60 ms)
variance introduced by outliers: 19% (moderately inflated)

* parsing and formatting times excluded
```



Day 23
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day23.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d23p]* / *[Code][d23g]* / *[Rendered][d23h]*

[d23p]: https://adventofcode.com/2018/day/23
[d23g]: https://github.com/mstksg/advent-of-code-2018/blob/master/src/AOC/Challenge/Day23.hs
[d23h]: https://mstksg.github.io/advent-of-code-2018/src/AOC.Challenge.Day23.html

*Reflection not yet written -- please check back later!*

### Day 23 Benchmarks

```
>> Day 23a
benchmarking...
time                 12.06 ms   (11.51 ms .. 12.88 ms)
                     0.986 R²   (0.979 R² .. 0.993 R²)
mean                 11.63 ms   (11.40 ms .. 11.93 ms)
std dev              695.8 μs   (529.8 μs .. 855.9 μs)
variance introduced by outliers: 27% (moderately inflated)

>> Day 23b
benchmarking...
time                 81.59 ms   (79.74 ms .. 83.22 ms)
                     0.999 R²   (0.998 R² .. 1.000 R²)
mean                 82.41 ms   (81.63 ms .. 83.17 ms)
std dev              1.247 ms   (975.9 μs .. 1.681 ms)
```



Day 24
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day24.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d24p]* / *[Code][d24g]* / *[Rendered][d24h]*

[d24p]: https://adventofcode.com/2018/day/24
[d24g]: https://github.com/mstksg/advent-of-code-2018/blob/master/src/AOC/Challenge/Day24.hs
[d24h]: https://mstksg.github.io/advent-of-code-2018/src/AOC.Challenge.Day24.html

*Reflection not yet written -- please check back later!*

### Day 24 Benchmarks

```
>> Day 24a
benchmarking...
time                 15.21 ms   (14.24 ms .. 16.16 ms)
                     0.986 R²   (0.975 R² .. 0.997 R²)
mean                 15.51 ms   (15.10 ms .. 15.84 ms)
std dev              960.8 μs   (673.2 μs .. 1.383 ms)
variance introduced by outliers: 28% (moderately inflated)

>> Day 24b
benchmarking...
time                 306.1 ms   (248.8 ms .. 363.7 ms)
                     0.992 R²   (0.976 R² .. 1.000 R²)
mean                 295.0 ms   (277.1 ms .. 302.1 ms)
std dev              14.25 ms   (1.339 ms .. 19.43 ms)
variance introduced by outliers: 16% (moderately inflated)
```



Day 25
------

<!--
This section is generated and compiled by the build script at ./Build.hs from
the file `./reflections/day25.md`.  If you want to edit this, edit
that file instead!
-->

*[Prompt][d25p]* / *[Code][d25g]* / *[Rendered][d25h]*

[d25p]: https://adventofcode.com/2018/day/25
[d25g]: https://github.com/mstksg/advent-of-code-2018/blob/master/src/AOC/Challenge/Day25.hs
[d25h]: https://mstksg.github.io/advent-of-code-2018/src/AOC.Challenge.Day25.html

*Reflection not yet written -- please check back later!*

### Day 25 Benchmarks

```
>> Day 25a
benchmarking...
time                 34.97 ms   (34.73 ms .. 35.38 ms)
                     1.000 R²   (0.999 R² .. 1.000 R²)
mean                 34.76 ms   (34.58 ms .. 35.00 ms)
std dev              454.5 μs   (351.5 μs .. 619.0 μs)

* parsing and formatting times excluded
```

